<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Performance Notes &mdash; Cassandra Driver 1.0.0 documentation</title>
    
    <link rel="stylesheet" href="_static/sphinxdoc.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '1.0.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <link rel="top" title="Cassandra Driver 1.0.0 documentation" href="index.html" />
    <link rel="prev" title="Getting Started" href="getting_started.html" /> 
  </head>
  <body>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="getting_started.html" title="Getting Started"
             accesskey="P">previous</a> |</li>
        <li><a href="index.html">Cassandra Driver 1.0.0 documentation</a> &raquo;</li> 
      </ul>
    </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
  <h3><a href="index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Performance Notes</a><ul>
<li><a class="reference internal" href="#benchmark-notes">Benchmark Notes</a></li>
<li><a class="reference internal" href="#synchronous-execution-sync-py">Synchronous Execution (sync.py)</a></li>
<li><a class="reference internal" href="#batched-futures-future-batches-py">Batched Futures (future_batches.py)</a></li>
<li><a class="reference internal" href="#queued-futures-future-full-pipeline-py">Queued Futures (future_full_pipeline.py)</a></li>
<li><a class="reference internal" href="#unthrottled-futures-future-full-throttle-py">Unthrottled Futures (future_full_throttle.py)</a></li>
<li><a class="reference internal" href="#callback-chaining-callbacks-full-pipeline-py">Callback Chaining (callbacks_full_pipeline.py)</a></li>
<li><a class="reference internal" href="#pypy">PyPy</a></li>
<li><a class="reference internal" href="#multiprocessing">multiprocessing</a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="getting_started.html"
                        title="previous chapter">Getting Started</a></p>
  <h3>This Page</h3>
  <ul class="this-page-menu">
    <li><a href="_sources/performance.txt"
           rel="nofollow">Show Source</a></li>
  </ul>
<div id="searchbox" style="display: none">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="performance-notes">
<h1>Performance Notes<a class="headerlink" href="#performance-notes" title="Permalink to this headline">¶</a></h1>
<p>The python driver for Cassandra offers several methods for executing queries.
You can synchronously block for queries to complete using
<a class="reference internal" href="api/cassandra/cluster.html#cassandra.cluster.Session.execute" title="cassandra.cluster.Session.execute"><tt class="xref py py-meth docutils literal"><span class="pre">Session.execute()</span></tt></a>, you can use a future-like interface through
<a class="reference internal" href="api/cassandra/cluster.html#cassandra.cluster.Session.execute_async" title="cassandra.cluster.Session.execute_async"><tt class="xref py py-meth docutils literal"><span class="pre">Session.execute_async()</span></tt></a>, or you can attach a callback to the future
with <a class="reference internal" href="api/cassandra/cluster.html#cassandra.cluster.ResponseFuture.add_callback" title="cassandra.cluster.ResponseFuture.add_callback"><tt class="xref py py-meth docutils literal"><span class="pre">ResponseFuture.add_callback()</span></tt></a>.  Each of these methods has
different performance characteristics and behaves differently when
multiple threads are used.</p>
<div class="section" id="benchmark-notes">
<h2>Benchmark Notes<a class="headerlink" href="#benchmark-notes" title="Permalink to this headline">¶</a></h2>
<p>All benchmarks were executed using the
<a class="reference external" href="https://github.com/datastax/python-driver/tree/master/benchmarks">benchmark scripts</a>
in the driver repository.  They were executed on a laptop with 16 GiB of RAM, an SSD,
and a 2 GHz, four core CPU with hyperthreading.  The Cassandra cluster was a three
node <a class="reference external" href="https://github.com/pcmanus/ccm">ccm</a> cluster running on the same laptop
with version 1.2.13 of Cassandra. I suggest testing these benchmarks against your
own cluster when tuning the driver for optimal throughput or latency.</p>
<p>The 1.0.0 version of the driver was used with all default settings.  For these
benchmarks, the driver was configured to use the <tt class="docutils literal"><span class="pre">libev</span></tt> reactor.  You can also run
the benchmarks using the <tt class="docutils literal"><span class="pre">asyncore</span></tt> event loop (<a class="reference internal" href="api/cassandra/io/asyncorereactor.html#cassandra.io.asyncorereactor.AsyncoreConnection" title="cassandra.io.asyncorereactor.AsyncoreConnection"><tt class="xref py py-class docutils literal"><span class="pre">AsyncoreConnection</span></tt></a>)
by using the <tt class="docutils literal"><span class="pre">--asyncore-only</span></tt> command line option.</p>
<p>Each benchmark completes 100,000 small inserts. The replication factor for the
keyspace was three, so all nodes were replicas for the inserted rows.</p>
</div>
<div class="section" id="synchronous-execution-sync-py">
<h2>Synchronous Execution (<a class="reference external" href="https://github.com/datastax/python-driver/blob/master/benchmarks/sync.py">sync.py</a>)<a class="headerlink" href="#synchronous-execution-sync-py" title="Permalink to this headline">¶</a></h2>
<p>Although this is the simplest way to make queries, it has low throughput
in single threaded environments.  This is basically what the benchmark
is doing:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">cassandra.cluster</span> <span class="kn">import</span> <span class="n">Cluster</span>

<span class="n">cluster</span> <span class="o">=</span> <span class="n">Cluster</span><span class="p">([</span><span class="mf">127.0</span><span class="o">.</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">127.0</span><span class="o">.</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">127.0</span><span class="o">.</span><span class="mf">0.3</span><span class="p">])</span>
<span class="n">session</span> <span class="o">=</span> <span class="n">cluster</span><span class="o">.</span><span class="n">connect</span><span class="p">()</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100000</span><span class="p">):</span>
    <span class="n">session</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="s">&quot;INSERT INTO mykeyspace.mytable (key, b, c) VALUES (a, &#39;b&#39;, &#39;c&#39;)&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-bash"><div class="highlight"><pre>~/python-driver <span class="nv">$ </span>python benchmarks/sync.py -n 100000 --hosts<span class="o">=</span>127.0.0.1,127.0.0.2,127.0.0.3 --libev-only --threads<span class="o">=</span>1
Average throughput: 434.08/sec
</pre></div>
</div>
<p>This technique does scale reasonably well as we add more threads:</p>
<div class="highlight-bash"><div class="highlight"><pre>~/python-driver <span class="nv">$ </span>python benchmarks/sync.py -n 100000 --hosts<span class="o">=</span>127.0.0.1,127.0.0.2,127.0.0.3 --libev-only --threads<span class="o">=</span>2
Average throughput: 830.49/sec
~/python-driver <span class="nv">$ </span>python benchmarks/sync.py -n 100000 --hosts<span class="o">=</span>127.0.0.1,127.0.0.2,127.0.0.3 --libev-only --threads<span class="o">=</span>4
Average throughput: 1078.27/sec
~/python-driver <span class="nv">$ </span>python benchmarks/sync.py -n 100000 --hosts<span class="o">=</span>127.0.0.1,127.0.0.2,127.0.0.3 --libev-only --threads<span class="o">=</span>8
Average throughput: 1275.20/sec
~/python-driver <span class="nv">$ </span>python benchmarks/sync.py -n 100000 --hosts<span class="o">=</span>127.0.0.1,127.0.0.2,127.0.0.3 --libev-only --threads<span class="o">=</span>16
Average throughput: 1345.56/sec
</pre></div>
</div>
<p>In my environment, throughput is maximized at about 20 threads.</p>
</div>
<div class="section" id="batched-futures-future-batches-py">
<h2>Batched Futures (<a class="reference external" href="https://github.com/datastax/python-driver/blob/master/benchmarks/future_batches.py">future_batches.py</a>)<a class="headerlink" href="#batched-futures-future-batches-py" title="Permalink to this headline">¶</a></h2>
<p>This is a simple way to work with futures for higher throughput.  Essentially,
we start 120 queries asynchronously at the same time and then wait for them
all to complete. We then repeat this process until all 100,000 operations
have completed:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">futures</span> <span class="o">=</span> <span class="n">Queue</span><span class="o">.</span><span class="n">Queue</span><span class="p">(</span><span class="n">maxsize</span><span class="o">=</span><span class="mi">121</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100000</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">120</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c"># clear the existing queue</span>
        <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">futures</span><span class="o">.</span><span class="n">get_nowait</span><span class="p">()</span><span class="o">.</span><span class="n">result</span><span class="p">()</span>
            <span class="k">except</span> <span class="n">Queue</span><span class="o">.</span><span class="n">Empty</span><span class="p">:</span>
                <span class="k">break</span>

    <span class="n">future</span> <span class="o">=</span> <span class="n">session</span><span class="o">.</span><span class="n">execute_async</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
    <span class="n">futures</span><span class="o">.</span><span class="n">put_nowait</span><span class="p">(</span><span class="n">future</span><span class="p">)</span>
</pre></div>
</div>
<p>As expected, this improves throughput in a single-threaded environment:</p>
<div class="highlight-bash"><div class="highlight"><pre>~/python-driver <span class="nv">$ </span>python benchmarks/future_batches.py -n 100000 --hosts<span class="o">=</span>127.0.0.1,127.0.0.2,127.0.0.3 --libev-only --threads<span class="o">=</span>1
Average throughput: 3477.56/sec
</pre></div>
</div>
<p>However, adding more threads may actually harm throughput:</p>
<div class="highlight-bash"><div class="highlight"><pre>~/python-driver <span class="nv">$ </span>python benchmarks/future_batches.py -n 100000 --hosts<span class="o">=</span>127.0.0.1,127.0.0.2,127.0.0.3 --libev-only --threads<span class="o">=</span>2
Average throughput: 2360.52/sec
~/python-driver <span class="nv">$ </span>python benchmarks/future_batches.py -n 100000 --hosts<span class="o">=</span>127.0.0.1,127.0.0.2,127.0.0.3 --libev-only --threads<span class="o">=</span>4
Average throughput: 2293.21/sec
~/python-driver <span class="nv">$ </span>python benchmarks/future_batches.py -n 100000 --hosts<span class="o">=</span>127.0.0.1,127.0.0.2,127.0.0.3 --libev-only --threads<span class="o">=</span>8
Average throughput: 2244.85/sec
</pre></div>
</div>
</div>
<div class="section" id="queued-futures-future-full-pipeline-py">
<h2>Queued Futures (<a class="reference external" href="https://github.com/datastax/python-driver/blob/master/benchmarks/future_full_pipeline.py">future_full_pipeline.py</a>)<a class="headerlink" href="#queued-futures-future-full-pipeline-py" title="Permalink to this headline">¶</a></h2>
<p>This pattern is similar to batched futures.  The main difference is that
every time we put a future on the queue, we pull the oldest future out
and wait for it to complete:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">futures</span> <span class="o">=</span> <span class="n">Queue</span><span class="o">.</span><span class="n">Queue</span><span class="p">(</span><span class="n">maxsize</span><span class="o">=</span><span class="mi">121</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100000</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;=</span> <span class="mi">120</span><span class="p">:</span>
        <span class="n">old_future</span> <span class="o">=</span> <span class="n">futures</span><span class="o">.</span><span class="n">get_nowait</span><span class="p">()</span>
        <span class="n">old_future</span><span class="o">.</span><span class="n">result</span><span class="p">()</span>

    <span class="n">future</span> <span class="o">=</span> <span class="n">session</span><span class="o">.</span><span class="n">execute_async</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
    <span class="n">futures</span><span class="o">.</span><span class="n">put_nowait</span><span class="p">(</span><span class="n">future</span><span class="p">)</span>
</pre></div>
</div>
<p>This gets slightly better throughput than the Batched Futures pattern:</p>
<div class="highlight-bash"><div class="highlight"><pre>~/python-driver <span class="nv">$ </span>python benchmarks/future_full_pipeline.py -n 100000 --hosts<span class="o">=</span>127.0.0.1,127.0.0.2,127.0.0.3 --libev-only --threads<span class="o">=</span>1
Average throughput: 3635.76/sec
</pre></div>
</div>
<p>But this has the same throughput issues when multiple threads are used:</p>
<div class="highlight-bash"><div class="highlight"><pre>~/python-driver <span class="nv">$ </span>python benchmarks/future_full_pipeline.py -n 100000 --hosts<span class="o">=</span>127.0.0.1,127.0.0.2,127.0.0.3 --libev-only --threads<span class="o">=</span>2
Average throughput: 2213.62/sec
~/python-driver <span class="nv">$ </span>python benchmarks/future_full_pipeline.py -n 100000 --hosts<span class="o">=</span>127.0.0.1,127.0.0.2,127.0.0.3 --libev-only --threads<span class="o">=</span>4
Average throughput: 2707.62/sec
~/python-driver <span class="nv">$ </span>python benchmarks/future_full_pipeline.py -n 100000 --hosts<span class="o">=</span>127.0.0.1,127.0.0.2,127.0.0.3 --libev-only --threads<span class="o">=</span>8
Average throughput: 2462.42/sec
</pre></div>
</div>
</div>
<div class="section" id="unthrottled-futures-future-full-throttle-py">
<h2>Unthrottled Futures (<a class="reference external" href="https://github.com/datastax/python-driver/blob/master/benchmarks/future_full_throttle.py">future_full_throttle.py</a>)<a class="headerlink" href="#unthrottled-futures-future-full-throttle-py" title="Permalink to this headline">¶</a></h2>
<p>What happens if we don&#8217;t throttle our async requests at all?</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">futures</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100000</span><span class="p">):</span>
    <span class="n">future</span> <span class="o">=</span> <span class="n">session</span><span class="o">.</span><span class="n">execute_async</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
    <span class="n">futures</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">future</span><span class="p">)</span>

<span class="k">for</span> <span class="n">future</span> <span class="ow">in</span> <span class="n">futures</span><span class="p">:</span>
    <span class="n">future</span><span class="o">.</span><span class="n">result</span><span class="p">()</span>
</pre></div>
</div>
<p>Throughput is about the same as the previous pattern, but a lot of memory will
be consumed by the list of Futures:</p>
<div class="highlight-bash"><div class="highlight"><pre>~/python-driver <span class="nv">$ </span>python benchmarks/future_full_throttle.py -n 100000 --hosts<span class="o">=</span>127.0.0.1,127.0.0.2,127.0.0.3 --libev-only --threads<span class="o">=</span>1
Average throughput: 3474.11/sec
~/python-driver <span class="nv">$ </span>python benchmarks/future_full_throttle.py -n 100000 --hosts<span class="o">=</span>127.0.0.1,127.0.0.2,127.0.0.3 --libev-only --threads<span class="o">=</span>2
Average throughput: 2389.61/sec
~/python-driver <span class="nv">$ </span>python benchmarks/future_full_throttle.py -n 100000 --hosts<span class="o">=</span>127.0.0.1,127.0.0.2,127.0.0.3 --libev-only --threads<span class="o">=</span>4
Average throughput: 2371.75/sec
~/python-driver <span class="nv">$ </span>python benchmarks/future_full_throttle.py -n 100000 --hosts<span class="o">=</span>127.0.0.1,127.0.0.2,127.0.0.3 --libev-only --threads<span class="o">=</span>8
Average throughput: 2165.29/sec
</pre></div>
</div>
</div>
<div class="section" id="callback-chaining-callbacks-full-pipeline-py">
<h2>Callback Chaining (<a class="reference external" href="https://github.com/datastax/python-driver/blob/master/benchmarks/callbacks_full_pipeline.py">callbacks_full_pipeline.py</a>)<a class="headerlink" href="#callback-chaining-callbacks-full-pipeline-py" title="Permalink to this headline">¶</a></h2>
<p>This pattern is very different from the previous patterns.  Here we&#8217;re taking
advantage of the <a class="reference internal" href="api/cassandra/cluster.html#cassandra.cluster.ResponseFuture.add_callback" title="cassandra.cluster.ResponseFuture.add_callback"><tt class="xref py py-meth docutils literal"><span class="pre">ResponseFuture.add_callback()</span></tt></a> function to start
another request as soon as one finishes.  Futhermore, we&#8217;re starting 120
of these callback chains, so we&#8217;ve always got about 120 operations in
flight at any time:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">itertools</span> <span class="kn">import</span> <span class="n">count</span>
<span class="kn">from</span> <span class="nn">threading</span> <span class="kn">import</span> <span class="n">Event</span>

<span class="n">num_started</span> <span class="o">=</span> <span class="n">count</span><span class="p">()</span>
<span class="n">num_finished</span> <span class="o">=</span> <span class="n">count</span><span class="p">()</span>
<span class="n">initial</span> <span class="o">=</span> <span class="nb">object</span><span class="p">()</span>
<span class="n">finished_event</span> <span class="o">=</span> <span class="n">Event</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">handle_error</span><span class="p">(</span><span class="n">exc</span><span class="p">):</span>
    <span class="n">log</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="s">&quot;Error on insert: </span><span class="si">%r</span><span class="s">&quot;</span><span class="p">,</span> <span class="n">exc</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">insert_next</span><span class="p">(</span><span class="n">previous_result</span><span class="p">):</span>
    <span class="n">current_num</span> <span class="o">=</span> <span class="n">num_started</span><span class="o">.</span><span class="n">next</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">previous_result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">initial</span><span class="p">:</span>
        <span class="n">num</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">num_finished</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">num</span> <span class="o">&gt;=</span> <span class="mi">100000</span><span class="p">:</span>
            <span class="n">finished_event</span><span class="o">.</span><span class="n">set</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">current_num</span> <span class="o">&lt;=</span> <span class="mi">100000</span><span class="p">:</span>
        <span class="n">future</span> <span class="o">=</span> <span class="n">session</span><span class="o">.</span><span class="n">execute_async</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
        <span class="n">future</span><span class="o">.</span><span class="n">add_callbacks</span><span class="p">(</span><span class="n">insert_next</span><span class="p">,</span> <span class="n">handle_error</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">120</span><span class="p">):</span>
    <span class="n">insert_next</span><span class="p">(</span><span class="n">initial</span><span class="p">)</span>

<span class="n">finished_event</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>
</pre></div>
</div>
<p>This is a more complex pattern, but the throughput is excellent:</p>
<div class="highlight-bash"><div class="highlight"><pre>~/python-driver <span class="nv">$ </span>python benchmarks/callback_full_pipeline.py -n 100000 --hosts<span class="o">=</span>127.0.0.1,127.0.0.2,127.0.0.3 --libev-only --threads<span class="o">=</span>1
Average throughput: 7647.30/sec
</pre></div>
</div>
<p>Part of the reason why performance is so good is that everything is running on
single thread: the internal event loop thread that powers the driver.  The
downside to this is that adding more threads doesn&#8217;t improve anything:</p>
<div class="highlight-bash"><div class="highlight"><pre>~/python-driver <span class="nv">$ </span>python benchmarks/callback_full_pipeline.py -n 100000 --hosts<span class="o">=</span>127.0.0.1,127.0.0.2,127.0.0.3 --libev-only --threads<span class="o">=</span>2
Average throughput: 7704.58/sec
</pre></div>
</div>
<p>What happens if we have more than 120 callback chains running?</p>
<p>With 250 chains:</p>
<div class="highlight-bash"><div class="highlight"><pre>~/python-driver <span class="nv">$ </span>python benchmarks/callback_full_pipeline.py -n 100000 --hosts<span class="o">=</span>127.0.0.1,127.0.0.2,127.0.0.3 --libev-only --threads<span class="o">=</span>1
Average throughput: 7794.22/sec
</pre></div>
</div>
<p>Things look pretty good with 250 chains.  If we try 500 chains, we start to max out
all of the connections in the connection pools.  The problem is that the current
version of the driver isn&#8217;t very good at throttling these callback chains, so
a lot of time gets spent waiting for new connections and performance drops
dramatically:</p>
<div class="highlight-bash"><div class="highlight"><pre>~/python-driver <span class="nv">$ </span>python benchmarks/callback_full_pipeline.py -n 100000 --hosts<span class="o">=</span>127.0.0.1,127.0.0.2,127.0.0.3 --libev-only --threads<span class="o">=</span>1
Average throughput: 679.61/sec
</pre></div>
</div>
<p>Until this is improved, you should limit the number of callback chains you run.</p>
</div>
<div class="section" id="pypy">
<h2>PyPy<a class="headerlink" href="#pypy" title="Permalink to this headline">¶</a></h2>
<p>Almost all of these patterns become CPU-bound pretty quickly with CPython, the
normal implementation of python. <a class="reference external" href="http://pypy.org">PyPy</a> is an alternative
implementation of Python (written in Python) which uses a JIT compiler to
reduce CPU consumption.  This leads to a huge improvement in the driver
performance:</p>
<div class="highlight-bash"><div class="highlight"><pre>~/python-driver <span class="nv">$ </span>pypy benchmarks/callback_full_pipeline.py -n 500000 --hosts<span class="o">=</span>127.0.0.1,127.0.0.2,127.0.0.3 --asyncore-only --threads<span class="o">=</span>1
Average throughput: 18782.00/sec
</pre></div>
</div>
<p>Eventually the driver may add C extensions to reduce CPU consumption, which
would probably narrow the gap between the performance of CPython and PyPy.</p>
</div>
<div class="section" id="multiprocessing">
<h2>multiprocessing<a class="headerlink" href="#multiprocessing" title="Permalink to this headline">¶</a></h2>
<p>All of the patterns here may be used over multiple processes using the
<a class="reference external" href="http://docs.python.org/2/library/multiprocessing.html">multiprocessing</a>
module.  Multiple processes will scale significantly better than multiple
threads will, so if high throughput is your goal, consider this option.</p>
<p>Just be sure to <strong>never share any</strong> <a class="reference internal" href="api/cassandra/cluster.html#cassandra.cluster.Cluster" title="cassandra.cluster.Cluster"><tt class="xref py py-class docutils literal"><span class="pre">Cluster</span></tt></a>, <a class="reference internal" href="api/cassandra/cluster.html#cassandra.cluster.Session" title="cassandra.cluster.Session"><tt class="xref py py-class docutils literal"><span class="pre">Session</span></tt></a>,
<strong>or</strong> <a class="reference internal" href="api/cassandra/cluster.html#cassandra.cluster.ResponseFuture" title="cassandra.cluster.ResponseFuture"><tt class="xref py py-class docutils literal"><span class="pre">ResponseFuture</span></tt></a> <strong>objects across multiple processes</strong>. These
objects should all be created after forking the process, not before.</p>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="getting_started.html" title="Getting Started"
             >previous</a> |</li>
        <li><a href="index.html">Cassandra Driver 1.0.0 documentation</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer">
        &copy; Copyright 2014, DataStax.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.2b1.
    </div>
  </body>
</html>